{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "municipal-runner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\metroide\\pycharmprojects\\speech\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\metroide\\pycharmprojects\\speech\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\metroide\\pycharmprojects\\speech\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\metroide\\pycharmprojects\\speech\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\metroide\\pycharmprojects\\speech\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\metroide\\pycharmprojects\\speech\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import Session\n",
    "import os\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = Session(config=config)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "superior-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_path = './train/audio/'\n",
    "all_wave = []\n",
    "all_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "controlling-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample\n",
    "labels = [\n",
    "    'left', 'go', 'yes', 'down', 'up', 'on', 'right', 'no', 'off', 'stop',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "interior-labor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [12:39<00:00, 75.93s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_audio_path = './datas/train/audio'\n",
    "\n",
    "all_wave = []\n",
    "all_label = []\n",
    "for label in tqdm(labels):\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.wav')]\n",
    "    for wav in waves:\n",
    "        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)\n",
    "        samples = librosa.resample(samples, sample_rate, 8000)\n",
    "        if(len(samples)== 8000) : \n",
    "            all_wave.append(samples)\n",
    "            all_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "tamil-authority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#remove this after oploading real dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "label_enconder = LabelEncoder()\n",
    "y = label_enconder.fit_transform(all_label)\n",
    "classes = list(label_enconder.classes_)\n",
    "y = np_utils.to_categorical(y, num_classes=len(labels))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "experimental-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape datas\n",
    "all_wave = np.array(all_wave).reshape(-1,8000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "expected-korea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create train and validation set 20% pour le text et 80% pour l'entrainement\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "stone-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional, BatchNormalization, CuDNNGRU, TimeDistributed, GRU\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "quick-overhead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8000, 1)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8000, 1)           4         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 7988, 8)           112       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 2662, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2662, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2652, 16)          1424      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 884, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 884, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 876, 32)           4640      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 292, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 292, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 292, 32)           128       \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 292, 128)          123648    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 292, 128)          197376    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               197376    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 560,814\n",
      "Trainable params: 560,492\n",
      "Non-trainable params: 322\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#definition du model en utilisaant keras\n",
    "inputs = Input(shape=(8000,1))\n",
    "x = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)(inputs)\n",
    "\n",
    "#First Conv1D layer\n",
    "x = Conv1D(8,13, padding='valid', activation='relu', strides=1)(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "#Second Conv1D layer\n",
    "x = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "#Third Conv1D layer\n",
    "x = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)(x)\n",
    "x = Bidirectional(GRU(128, return_sequences=True), merge_mode='sum')(x)\n",
    "x = Bidirectional(GRU(128, return_sequences=True), merge_mode='sum')(x)\n",
    "x = Bidirectional(GRU(128, return_sequences=False), merge_mode='sum')(x)\n",
    "x = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)(x)\n",
    "\n",
    "#Flatten layer\n",
    "# x = Flatten()(x)\n",
    "#Dense Layer 1\n",
    "x = Dense(256, activation='relu')(x)\n",
    "outputs = Dense(len(labels), activation=\"softmax\")(x)\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "lightweight-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilation du model en utilisant la fonction d'erreur caegorical cross entropie\n",
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "#definition des differents callback pour l'arret du model et sauvegarde du meilleur model\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15, min_delta=0.0001) \n",
    "checkpoint = ModelCheckpoint('speech2text_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-requirement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\metroide\\pycharmprojects\\speech\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 17049 samples, validate on 4263 samples\n",
      "Epoch 1/100\n",
      "17049/17049 [==============================] - 1359s 80ms/step - loss: 1.2798 - acc: 0.5397 - val_loss: 0.9819 - val_acc: 0.6716\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.67159, saving model to speech2text_model.hdf5\n",
      "Epoch 2/100\n",
      "17049/17049 [==============================] - 1481s 87ms/step - loss: 0.6868 - acc: 0.7647 - val_loss: 0.6834 - val_acc: 0.7795\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.67159 to 0.77950, saving model to speech2text_model.hdf5\n",
      "Epoch 3/100\n",
      "17049/17049 [==============================] - 1433s 84ms/step - loss: 0.5310 - acc: 0.8165 - val_loss: 0.5535 - val_acc: 0.8198\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.77950 to 0.81985, saving model to speech2text_model.hdf5\n",
      "Epoch 4/100\n",
      "17049/17049 [==============================] - 1566s 92ms/step - loss: 0.4686 - acc: 0.8429 - val_loss: 0.3943 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.81985 to 0.86700, saving model to speech2text_model.hdf5\n",
      "Epoch 5/100\n",
      "17049/17049 [==============================] - 1732s 102ms/step - loss: 0.4221 - acc: 0.8549 - val_loss: 0.3968 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.86700 to 0.87051, saving model to speech2text_model.hdf5\n",
      "Epoch 6/100\n",
      "17049/17049 [==============================] - 1739s 102ms/step - loss: 0.3856 - acc: 0.8677 - val_loss: 0.5972 - val_acc: 0.8025\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.87051\n",
      "Epoch 7/100\n",
      "17049/17049 [==============================] - 1725s 101ms/step - loss: 0.3856 - acc: 0.8683 - val_loss: 0.3889 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.87051 to 0.87450, saving model to speech2text_model.hdf5\n",
      "Epoch 8/100\n",
      "17049/17049 [==============================] - 1543s 91ms/step - loss: 0.3683 - acc: 0.8751 - val_loss: 0.3229 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.87450 to 0.89022, saving model to speech2text_model.hdf5\n",
      "Epoch 9/100\n",
      "17049/17049 [==============================] - 1357s 80ms/step - loss: 0.3483 - acc: 0.8818 - val_loss: 0.4230 - val_acc: 0.8590\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.89022\n",
      "Epoch 10/100\n",
      "17049/17049 [==============================] - 1329s 78ms/step - loss: 0.3755 - acc: 0.8738 - val_loss: 0.3554 - val_acc: 0.8872\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.89022\n",
      "Epoch 11/100\n",
      "17049/17049 [==============================] - 1321s 77ms/step - loss: 0.3371 - acc: 0.8880 - val_loss: 0.4929 - val_acc: 0.8325\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.89022\n",
      "Epoch 12/100\n",
      "17049/17049 [==============================] - 1329s 78ms/step - loss: 0.3389 - acc: 0.8861 - val_loss: 0.3372 - val_acc: 0.8851\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.89022\n",
      "Epoch 13/100\n",
      "16064/17049 [===========================>..] - ETA: 1:11 - loss: 0.3233 - acc: 0.8898"
     ]
    }
   ],
   "source": [
    "#entrainement du model avec un batch size de 32 sur le CPU.\n",
    "hist = model.fit(\n",
    "    x=x_train, \n",
    "    y=y_train,\n",
    "    epochs=100, \n",
    "    callbacks=[early_stop, checkpoint], \n",
    "    batch_size=32, \n",
    "    validation_data=(x_valid,y_valid)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
